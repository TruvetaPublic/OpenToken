name: Core CI

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main", "develop"]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  MIN_COVERAGE_OVERALL: 60
  MIN_COVERAGE_CHANGED_FILES: 80
  MIN_COVERAGE_OVERALL_RATIO: 0.6
  MIN_COVERAGE_CHANGED_FILES_RATIO: 0.8

jobs:
  java-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      checks: write
      pull-requests: write
      statuses: write
      actions: read
      security-events: write
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Java)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-python: false

      - name: Build and test with Maven
        run: cd lib/java && mvn -B package --file pom.xml

      - name: Publish Maven Surefire report
        if: success() || failure()
        uses: scacap/action-surefire-report@v1

      - name: Publish Java unit test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: |
            lib/java/opentoken/target/surefire-reports/*.xml
            lib/java/opentoken-cli/target/surefire-reports/*.xml
          check_name: Java Test Results
          comment_mode: always
          compare_to_earlier_commit: false

      - name: Generate JaCoCo report
        run: cd lib/java && mvn jacoco:report

      - name: Upload JaCoCo artifact
        uses: actions/upload-artifact@v4
        with:
          name: java-code-coverage
          path: |
            lib/java/opentoken/target/site/jacoco/*
            lib/java/opentoken-cli/target/site/jacoco/*

      - name: Add Java code coverage to PR
        uses: madrapps/jacoco-report@v1.7.1
        with:
          paths: |
            lib/java/opentoken/target/site/jacoco/jacoco.xml,
            lib/java/opentoken-cli/target/site/jacoco/jacoco.xml
          token: ${{ secrets.GITHUB_TOKEN }}
          title: Code Coverage
          min-coverage-overall: ${{ env.MIN_COVERAGE_OVERALL }}
          min-coverage-changed-files: ${{ env.MIN_COVERAGE_CHANGED_FILES }}
          pass-emoji: ":green_circle:"
          fail-emoji: ":red_circle:"
          update-comment: true

      - name: Update dependency graph
        uses: advanced-security/maven-dependency-submission-action@v3
        with:
          directory: ${{ github.workspace }}/lib/java
          maven-args: "-B -DskipTests"

  java-cli-smoke:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
    strategy:
      matrix:
        file-type: ["csv", "parquet"]
    env:
      INPUT_TYPE: ${{ matrix.file-type }}
      INPUT_FILE: ${{ github.workspace }}/resources/sample.${{ matrix.file-type }}
      OUTPUT_TYPE: ${{ matrix.file-type }}
      OUTPUT_ZIP: target/output-${{ matrix.file-type }}.zip
      DECRYPTED_FILE: target/decrypted.${{ matrix.file-type }}
      HASH_ONLY_FILE: target/hash_only_output.${{ matrix.file-type }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Java + Python for Parquet compare)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-java: true
          enable-python: true
          python-version: "3.10"

      - name: Build Java CLI
        run: |
          cd lib/java
          mvn -B -pl opentoken-cli -am package -DskipTests

      - name: Install Python compare dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow

      - name: Run CLI smoke test (ECDH key exchange)
        run: |
          cd lib/java/opentoken-cli
          mkdir -p target keys
          CLI_JAR=$(ls target/opentoken-cli-*.jar | head -n 1)
          if [ -z "$CLI_JAR" ]; then
            echo "Error: opentoken-cli jar not found"
            exit 1
          fi

          # Generate receiver keypair
          java -jar "$CLI_JAR" generate-keypair --output-dir target/keys/receiver --ecdh-curve P-384

          # Generate sender keypair
          java -jar "$CLI_JAR" generate-keypair --output-dir target/keys/sender --ecdh-curve P-384

          # Tokenize with ECDH (sender creates encrypted tokens)
          java -jar "$CLI_JAR" tokenize \
            -i "$INPUT_FILE" \
            -t "$INPUT_TYPE" \
            -o "$OUTPUT_ZIP" \
            --receiver-public-key target/keys/receiver/public_key.pem \
            --sender-keypair-path target/keys/sender/keypair.pem \
            --ecdh-curve P-384 \
            -ot "$OUTPUT_TYPE"

          # Decrypt tokens with ECDH (receiver decrypts)
          java -jar "$CLI_JAR" decrypt \
            -i "$OUTPUT_ZIP" \
            -t "$OUTPUT_TYPE" \
            -o "$DECRYPTED_FILE" \
            --receiver-keypair-path target/keys/receiver/keypair.pem \
            -ot "$OUTPUT_TYPE"

          # Tokenize with hash-only mode (no encryption)
          java -jar "$CLI_JAR" tokenize \
            -i "$INPUT_FILE" \
            -t "$INPUT_TYPE" \
            -o "$HASH_ONLY_FILE" \
            -ot "$OUTPUT_TYPE" \
            --receiver-public-key target/keys/receiver/public_key.pem \
            --sender-keypair-path target/keys/sender/keypair.pem \
            --hash-only

      - name: Validate CLI output files
        run: |
          cd lib/java/opentoken-cli
          if [ ! -f "$OUTPUT_ZIP" ]; then
            echo "Error: $OUTPUT_ZIP not created"
            exit 1
          fi
          if [ ! -f "$DECRYPTED_FILE" ]; then
            echo "Error: $DECRYPTED_FILE not created"
            exit 1
          fi
          if [ ! -f "$HASH_ONLY_FILE" ]; then
            echo "Error: $HASH_ONLY_FILE not created"
            exit 1
          fi

      - name: Compare decrypted and hash-only outputs
        run: |
          cd lib/java/opentoken-cli
          python3 << 'EOF'
          import csv
          import os

          def extract_tokens_by_record(file_path, file_type):
            """Extract tokens grouped by record ID and rule ID."""
            records = {}
            if file_type == "parquet":
              import pandas as pd
              df = pd.read_parquet(file_path)
              for _, row in df.iterrows():
                record_id = row.get('RecordId', '')
                rule_id = row.get('RuleId', '')
                token = row.get('Token', '')
                if record_id and rule_id:
                  records.setdefault(record_id, {})[rule_id] = token
              return records

            with open(file_path, 'r') as f:
              reader = csv.DictReader(f)
              for row in reader:
                record_id = row.get('RecordId', '')
                rule_id = row.get('RuleId', '')
                token = row.get('Token', '')
                if record_id and rule_id:
                  records.setdefault(record_id, {})[rule_id] = token
            return records

          file_type = os.environ.get("OUTPUT_TYPE", "csv")
          decrypted_file = os.environ.get("DECRYPTED_FILE", "target/decrypted.csv")
          hash_only_file = os.environ.get("HASH_ONLY_FILE", "target/hash_only_output.csv")

          decrypted = extract_tokens_by_record(decrypted_file, file_type)
          hash_only = extract_tokens_by_record(hash_only_file, file_type)

          shared_records = set(decrypted.keys()) & set(hash_only.keys())
          print(f"Comparing {len(shared_records)} shared records...")
          print(f"  Decrypted has {len(decrypted)} total records")
          print(f"  Hash-only has {len(hash_only)} total records")

          mismatches = 0
          for record_id in sorted(shared_records):
              dec_tokens = decrypted[record_id]
              hash_tokens = hash_only[record_id]

              shared_rules = set(dec_tokens.keys()) & set(hash_tokens.keys())
              for rule in sorted(shared_rules):
                  dec_val = dec_tokens[rule]
                  hash_val = hash_tokens[rule]
                  if dec_val != hash_val:
                      print(f"Mismatch in record {record_id}, rule {rule}:")
                      print(f"  Decrypted: {dec_val[:64]}...")
                      print(f"  Hash-only: {hash_val[:64]}...")
                      mismatches += 1

          if mismatches == 0:
              print("✓ Success: All tokens match for shared records and token rules")
          else:
              print(f"✗ Error: Found {mismatches} token mismatches")
              exit(1)
          EOF

      - name: Validate CLI output content
        run: |
          cd lib/java/opentoken-cli
          python3 << 'EOF'
          import os

          file_type = os.environ.get("OUTPUT_TYPE", "csv")
          decrypted_file = os.environ.get("DECRYPTED_FILE", "target/decrypted.csv")

          if file_type == "parquet":
              import pandas as pd
              df = pd.read_parquet(decrypted_file)
              line_count = len(df) + 1
          else:
              with open(decrypted_file, "r") as f:
                  line_count = sum(1 for _ in f)

          if line_count <= 1:
              raise SystemExit("Error: Decrypted file appears to be empty or only contains headers")

          print(f"Decrypted file contains {line_count} lines")
          EOF

  python-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write
      actions: read
      packages: write
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Python)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-java: false
          enable-python: true
          python-version: ${{ matrix.python-version }}

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r lib/python/opentoken/requirements.txt
          pip install pytest pytest-cov flake8
          pip install -e lib/python/opentoken/

      - name: Lint with flake8
        run: |
          flake8 lib/python/opentoken/src --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 lib/python/opentoken/src --count --exit-zero --statistics

      - name: Test with pytest
        run: |
          PYTHONPATH=lib/python/opentoken/src/main pytest lib/python/opentoken/src/test --junitxml=lib/python/opentoken/test-results-${{ matrix.python-version }}.xml --cov=lib/python/opentoken/src/main --cov-report=xml:lib/python/opentoken/coverage.xml --cov-report=html:lib/python/opentoken/htmlcov

      - name: Upload Python coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: python-code-coverage-${{ matrix.python-version }}
          path: |
            lib/python/opentoken/coverage.xml
            lib/python/opentoken/htmlcov/*

      - name: Publish Python unit test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: |
            lib/python/opentoken/test-results-${{ matrix.python-version }}.xml
          check_name: Python ${{ matrix.python-version }} Test Results
          comment_mode: always
          compare_to_earlier_commit: false

      # TODO: Re-enable once issues with correct threshold calculation and reporting are resolved in orgoro/coverage action
      # - name: Add Python code coverage to PR
      #   if: matrix.python-version == '3.10'
      #   uses: orgoro/coverage@v3.2
      #   with:
      #     coverageFile: lib/python/opentoken/coverage.xml
      #     token: ${{ secrets.GITHUB_TOKEN }}
      #     thresholdAll: ${{ env.MIN_COVERAGE_OVERALL_RATIO }}
      #     thresholdNew: ${{ env.MIN_COVERAGE_CHANGED_FILES_RATIO }}
      #     thresholdModified: ${{ env.MIN_COVERAGE_CHANGED_FILES_RATIO }}
      #     sourceDir: lib/python/opentoken/src/main

  python-cli-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write
      actions: read
      packages: write
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Python)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-java: false
          enable-python: true
          python-version: ${{ matrix.python-version }}

      - name: Install Python CLI dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r lib/python/opentoken/requirements.txt
          pip install -e lib/python/opentoken/
          pip install -r lib/python/opentoken-cli/requirements.txt
          pip install pytest pytest-cov flake8
          pip install -e lib/python/opentoken-cli/

      - name: Lint CLI with flake8
        run: |
          flake8 lib/python/opentoken-cli/src --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 lib/python/opentoken-cli/src --count --exit-zero --statistics

      - name: Test CLI with pytest
        run: |
          PYTHONPATH=lib/python/opentoken/src/main:lib/python/opentoken-cli/src/main pytest lib/python/opentoken-cli/src/test --junitxml=lib/python/opentoken-cli/test-results-${{ matrix.python-version }}.xml --cov=lib/python/opentoken-cli/src/main --cov-report=xml:lib/python/opentoken-cli/coverage.xml --cov-report=html:lib/python/opentoken-cli/htmlcov

      - name: Upload Python CLI coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: python-cli-code-coverage-${{ matrix.python-version }}
          path: |
            lib/python/opentoken-cli/coverage.xml
            lib/python/opentoken-cli/htmlcov/*

      - name: Publish Python CLI test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: |
            lib/python/opentoken-cli/test-results-${{ matrix.python-version }}.xml
          check_name: Python CLI ${{ matrix.python-version }} Test Results
          comment_mode: always
          compare_to_earlier_commit: false

  python-cli-smoke:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
    strategy:
      matrix:
        file-type: ["csv", "parquet"]
    env:
      INPUT_TYPE: ${{ matrix.file-type }}
      INPUT_FILE: ${{ github.workspace }}/resources/sample.${{ matrix.file-type }}
      OUTPUT_TYPE: ${{ matrix.file-type }}
      OUTPUT_ZIP: target/output-${{ matrix.file-type }}.zip
      DECRYPTED_FILE: target/decrypted.${{ matrix.file-type }}
      HASH_ONLY_FILE: target/hash_only_output.${{ matrix.file-type }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Python)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-java: false
          enable-python: true
          python-version: "3.10"

      - name: Install Python CLI dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r lib/python/opentoken/requirements.txt
          pip install -e lib/python/opentoken/
          pip install -r lib/python/opentoken-cli/requirements.txt
          pip install -e lib/python/opentoken-cli/

      - name: Run CLI smoke test (ECDH key exchange)
        run: |
          cd lib/python/opentoken-cli
          mkdir -p target keys

          # Generate receiver keypair
          opentoken generate-keypair --output-dir target/keys/receiver

          # Generate sender keypair
          opentoken generate-keypair --output-dir target/keys/sender

          # Tokenize with ECDH (sender creates encrypted tokens)
          opentoken tokenize \
            -i "$INPUT_FILE" \
            -t "$INPUT_TYPE" \
            -o "$OUTPUT_ZIP" \
            --receiver-public-key target/keys/receiver/public_key.pem \
            --sender-keypair-path target/keys/sender/keypair.pem \
            --ecdh-curve P-384 \
            -ot "$OUTPUT_TYPE"

          # Decrypt tokens with ECDH (receiver decrypts)
          opentoken decrypt \
            -i "$OUTPUT_ZIP" \
            -t "$OUTPUT_TYPE" \
            -o "$DECRYPTED_FILE" \
            --receiver-keypair-path target/keys/receiver/keypair.pem \
            -ot "$OUTPUT_TYPE"

          # Tokenize with hash-only mode (no encryption)
          opentoken tokenize \
            -i "$INPUT_FILE" \
            -t "$INPUT_TYPE" \
            -o "$HASH_ONLY_FILE" \
            -ot "$OUTPUT_TYPE" \
            --receiver-public-key target/keys/receiver/public_key.pem \
            --sender-keypair-path target/keys/sender/keypair.pem \
            --hash-only

      - name: Validate CLI output files
        run: |
          cd lib/python/opentoken-cli
          if [ ! -f "$OUTPUT_ZIP" ]; then
            echo "Error: $OUTPUT_ZIP not created"
            exit 1
          fi
          if [ ! -f "$DECRYPTED_FILE" ]; then
            echo "Error: $DECRYPTED_FILE not created"
            exit 1
          fi
          if [ ! -f "$HASH_ONLY_FILE" ]; then
            echo "Error: $HASH_ONLY_FILE not created"
            exit 1
          fi

      - name: Compare decrypted and hash-only outputs
        run: |
          cd lib/python/opentoken-cli
          # Extract token columns (T1-T5) from both files and compare
          # Skip the metadata.json files and compare just the CSV/Parquet data
          python3 << 'EOF'
          import csv
          import os

          def extract_tokens_by_record(file_path, file_type):
            """Extract tokens grouped by record ID and rule ID."""
            records = {}
            if file_type == "parquet":
              import pandas as pd
              df = pd.read_parquet(file_path)
              for _, row in df.iterrows():
                record_id = row.get('RecordId', '')
                rule_id = row.get('RuleId', '')
                token = row.get('Token', '')
                if record_id and rule_id:
                  records.setdefault(record_id, {})[rule_id] = token
              return records

            with open(file_path, 'r') as f:
              reader = csv.DictReader(f)
              for row in reader:
                record_id = row.get('RecordId', '')
                rule_id = row.get('RuleId', '')
                token = row.get('Token', '')
                if record_id and rule_id:
                  records.setdefault(record_id, {})[rule_id] = token
            return records

          file_type = os.environ.get("OUTPUT_TYPE", "csv")
          decrypted_file = os.environ.get("DECRYPTED_FILE", "target/decrypted.csv")
          hash_only_file = os.environ.get("HASH_ONLY_FILE", "target/hash_only_output.csv")

          decrypted = extract_tokens_by_record(decrypted_file, file_type)
          hash_only = extract_tokens_by_record(hash_only_file, file_type)

          # Find shared records (encryption may skip records with all blank tokens)
          shared_records = set(decrypted.keys()) & set(hash_only.keys())
          print(f"Comparing {len(shared_records)} shared records...")
          print(f"  Decrypted has {len(decrypted)} total records")
          print(f"  Hash-only has {len(hash_only)} total records")

          mismatches = 0
          for record_id in sorted(shared_records):
              dec_tokens = decrypted[record_id]
              hash_tokens = hash_only[record_id]

              # Only compare token rules that exist in BOTH outputs
              # Encrypted output may skip blank tokens that hash-only includes
              shared_rules = set(dec_tokens.keys()) & set(hash_tokens.keys())
              for rule in sorted(shared_rules):
                  dec_val = dec_tokens[rule]
                  hash_val = hash_tokens[rule]
                  if dec_val != hash_val:
                      print(f"Mismatch in record {record_id}, rule {rule}:")
                      print(f"  Decrypted: {dec_val[:64]}...")
                      print(f"  Hash-only: {hash_val[:64]}...")
                      mismatches += 1

          if mismatches == 0:
              print("✓ Success: All tokens match for shared records and token rules")
          else:
              print(f"✗ Error: Found {mismatches} token mismatches")
              exit(1)
          EOF

      - name: Validate CLI output content
        run: |
          cd lib/python/opentoken-cli
          python3 << 'EOF'
          import os

          file_type = os.environ.get("OUTPUT_TYPE", "csv")
          decrypted_file = os.environ.get("DECRYPTED_FILE", "target/decrypted.csv")

          if file_type == "parquet":
              import pandas as pd
              df = pd.read_parquet(decrypted_file)
              line_count = len(df) + 1
          else:
              with open(decrypted_file, "r") as f:
                  line_count = sum(1 for _ in f)

          if line_count <= 1:
              raise SystemExit("Error: Decrypted file appears to be empty or only contains headers")

          print(f"Decrypted file contains {line_count} lines")
          EOF

  pyspark-bridge-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write
      actions: read
      packages: write
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        spark-version: ["3.4", "3.5", "4.0", "4.1"]
    steps:
      - uses: actions/checkout@v4

      - name: Setup toolchain (Python + Java for PySpark)
        uses: ./.github/actions/setup-toolchain
        with:
          enable-java: true # PySpark requires Java
          enable-python: true
          python-version: ${{ matrix.python-version }}
          # Spark 3.4/3.5 require Java 8-17, Spark 4.0+ requires Java 21
          java-version: ${{ (matrix.spark-version == '4.0' || matrix.spark-version == '4.1') && '21' || '17' }}

      - name: Install OpenToken core library
        run: |
          python -m pip install --upgrade pip
          pip install -r lib/python/opentoken/requirements.txt
          pip install -e lib/python/opentoken/

      - name: Install PySpark bridge dependencies (Spark ${{ matrix.spark-version }})
        run: |
          pip install pytest pytest-cov flake8
          if [ "${{ matrix.spark-version }}" = "4.0" ]; then
            pip install -e "lib/python/opentoken-pyspark[spark40]"
          elif [ "${{ matrix.spark-version }}" = "4.1" ]; then
            pip install -e "lib/python/opentoken-pyspark[spark41]"
          elif [ "${{ matrix.spark-version }}" = "3.4" ]; then
            pip install -e "lib/python/opentoken-pyspark[spark34]"
          elif [ "${{ matrix.spark-version }}" = "3.5" ]; then
            pip install -e "lib/python/opentoken-pyspark[spark35]"
          else
            echo "Unsupported Spark version for PySpark bridge: '${{ matrix.spark-version }}'."
            echo "Please update .github/workflows/ci.yml to handle this Spark version."
            exit 1
          fi
          pip install -r lib/python/opentoken-pyspark/dev-requirements.txt

      - name: Lint with flake8
        run: |
          flake8 lib/python/opentoken-pyspark/src/main/opentoken_pyspark --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 lib/python/opentoken-pyspark/src/main/opentoken_pyspark --count --exit-zero --statistics

      - name: Test PySpark bridge
        run: |
          PYTHONPATH=lib/python/opentoken/src/main:lib/python/opentoken-pyspark/src/main pytest lib/python/opentoken-pyspark/src/test --junitxml=lib/python/opentoken-pyspark/test-results-${{ matrix.python-version }}-spark${{ matrix.spark-version }}.xml --cov=lib/python/opentoken-pyspark/src/main/opentoken_pyspark --cov-report=xml:lib/python/opentoken-pyspark/coverage-${{ matrix.python-version }}-spark${{ matrix.spark-version }}.xml --cov-report=html:lib/python/opentoken-pyspark/htmlcov-${{ matrix.python-version }}-spark${{ matrix.spark-version }}

      - name: Upload PySpark coverage artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pyspark-code-coverage-${{ matrix.python-version }}-spark${{ matrix.spark-version }}
          path: |
            lib/python/opentoken-pyspark/coverage-${{ matrix.python-version }}-spark${{ matrix.spark-version }}.xml
            lib/python/opentoken-pyspark/htmlcov-${{ matrix.python-version }}-spark${{ matrix.spark-version }}/*

      - name: Publish PySpark test results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: |
            lib/python/opentoken-pyspark/test-results-${{ matrix.python-version }}-spark${{ matrix.spark-version }}.xml
          check_name: PySpark Bridge ${{ matrix.python-version }} Spark ${{ matrix.spark-version }} Test Results
          comment_mode: always
          compare_to_earlier_commit: false

      - name: Add PySpark code coverage to PR
        if: matrix.python-version == '3.10' && matrix.spark-version == '4.0'
        uses: orgoro/coverage@v3.2
        with:
          coverageFile: lib/python/opentoken-pyspark/coverage-${{ matrix.python-version }}-spark${{ matrix.spark-version }}.xml
          token: ${{ secrets.GITHUB_TOKEN }}
          thresholdAll: ${{ env.MIN_COVERAGE_OVERALL_RATIO }}
          thresholdNew: ${{ env.MIN_COVERAGE_CHANGED_FILES_RATIO }}
          thresholdModified: ${{ env.MIN_COVERAGE_CHANGED_FILES_RATIO }}
          sourceDir: lib/python/opentoken-pyspark/src/main

  interoperability-tests:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      actions: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup toolchain (Java + Python)
        uses: ./.github/actions/setup-toolchain
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          cd lib/python/opentoken
          pip install -e .
          cd ../opentoken-cli
          pip install -e .
          cd ../opentoken-pyspark
          pip install -e .[spark40]

      - name: Install interoperability tool dependencies
        run: |
          cd tools
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Build Java artifacts
        run: |
          cd lib/java
          mvn clean package -DskipTests

      - name: Run interoperability tests
        id: run-tests
        run: |
          cd tools/interoperability
          python java_python_interoperability_test.py

      - name: Upload interoperability artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: interoperability-test-results
          path: |
            /tmp/*output*.csv
            /tmp/*decrypted*.csv
            tools/interoperability/*.log
          retention-days: 7

      - name: Summarize interoperability results
        if: always()
        run: |
          if [ "${{ steps.run-tests.outcome }}" = "success" ]; then
            {
              echo "## Interoperability Tests Passed"
              echo
              echo "Both implementations produced matching encrypted and decrypted tokens."
              echo
              echo "**Environment:** Java 21 + Python 3.10 on Ubuntu"
            } >> "$GITHUB_STEP_SUMMARY"
          else
            {
              echo "## Interoperability Tests Failed"
              echo
              echo "Check the job logs and uploaded artifacts for comparison details."
            } >> "$GITHUB_STEP_SUMMARY"
          fi
